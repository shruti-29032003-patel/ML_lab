{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shruti-29032003-patel/ML_lab_CE104/blob/main/ML_Lab12_CE104.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OjE_JneRT9E"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import tensorflow\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "IX_g7UGWZ21I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size, epoch and iteration\n",
        "batch_size = 100\n",
        "n_iters = 5000\n",
        "num_epochs = n_iters / (len(train_loader) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "print(num_epochs)"
      ],
      "metadata": {
        "id": "AMncN8SPaFYm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0cd8cf7-cc46-4359-f5c2-1b2142a07fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the artificial neural network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Fy_Uk0RkfZiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the neural network and optimizer\n",
        "input_dim = 28*28\n",
        "hidden_dim = 150\n",
        "output_dim = 10\n",
        "net = Net(input_dim, hidden_dim, output_dim)\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.02)\n",
        "print(num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTA_C3dpuTkm",
        "outputId": "1d86fe16-8bb3-4627-c544-30f72299ccc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the neural network\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "count = 0\n",
        "\n",
        "for epoch in range(20):\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = nn.functional.cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        count += 1\n",
        "\n",
        "        # Print training progress\n",
        "        if count % 50 == 0:\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "              for inputs, labels in test_loader:\n",
        "                  outputs = net(inputs)\n",
        "                  _, predicted = torch.max(outputs.data, 1)\n",
        "                  total += labels.size(0)\n",
        "                  correct += (predicted == labels).sum().item()\n",
        "            accuracy = 100 * correct / total\n",
        "            accuracy_list.append(accuracy)\n",
        "\n",
        "        if count % 500 == 0:\n",
        "          # visualization loss\n",
        "          print('Iteration: {} Loss: {} Accuracy: {} %'.format(count, loss.data, accuracy))\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g67oBGwe0B5A",
        "outputId": "2ef8c7dd-c4b7-43f7-b83b-f4b51f71192a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500 Loss: 0.5153708457946777 Accuracy: 90.96 %\n",
            "Iteration: 1000 Loss: 0.2832004725933075 Accuracy: 92.75 %\n",
            "Iteration: 1500 Loss: 0.21873120963573456 Accuracy: 93.93 %\n",
            "Iteration: 2000 Loss: 0.3681122362613678 Accuracy: 94.24 %\n",
            "Iteration: 2500 Loss: 0.29156240820884705 Accuracy: 95.13 %\n",
            "Iteration: 3000 Loss: 0.1334780752658844 Accuracy: 95.4 %\n",
            "Iteration: 3500 Loss: 0.2600698471069336 Accuracy: 95.74 %\n",
            "Iteration: 4000 Loss: 0.1541985422372818 Accuracy: 96.1 %\n",
            "Iteration: 4500 Loss: 0.03227430209517479 Accuracy: 96.27 %\n",
            "Iteration: 5000 Loss: 0.1350422501564026 Accuracy: 96.47 %\n",
            "Iteration: 5500 Loss: 0.07251352071762085 Accuracy: 96.77 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(iteration_list,loss_list)\n",
        "plt.xlabel(\"Number of iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"ANN: Loss vs Number of iteration\")\n",
        "plt.show()\n",
        "# visualization accuracy\n",
        "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
        "plt.xlabel(\"Number of iteration\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"ANN: Accuracy vs Number of iteration\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0NFme35N0LzA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}